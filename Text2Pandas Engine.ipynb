{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraElwatany/Text2Pandas-Engine/blob/main/Text2Pandas%20Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text2Pandas command engine**\n",
        "\n",
        "Two approaches to construct the Text2Pandas command engine:\n",
        "\n",
        "**1. First approach:** depends on fully automating the process using llm models like (LLama3, open source model) and Pandasai framework , to perform question answering on our dataframe (**Section 2**)\n",
        "\n",
        "\n",
        "\n",
        "**2. Second approach:** depends on using llm models like (LLama3, open source model) to extract information in the form of a dictionary, the dictionary will always have the same structure meaning the same keys and only the values of the keys will change based on the parsed data from the llm, and then using the parsed data we would map the values present in it with a predefined python code which will generate the pandas commands (**Section 3**)"
      ],
      "metadata": {
        "id": "7yKs_2KhLt5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries to install (Assuming you are using Google Colab)\n",
        "!pip install pandasai\n",
        "!pip install langchain\n",
        "!pip install langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "56FS5rcKM61N",
        "outputId": "d48fbe90-de54-4fbe-e020-9630296b82dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandasai\n",
            "  Downloading pandasai-2.2.14-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting astor<0.9.0,>=0.8.1 (from pandasai)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting duckdb<2.0.0,>=1.0.0 (from pandasai)\n",
            "  Downloading duckdb-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (762 bytes)\n",
            "Collecting faker<20.0.0,>=19.12.0 (from pandasai)\n",
            "  Downloading Faker-19.13.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from pandasai) (3.1.4)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from pandasai) (3.7.1)\n",
            "Collecting openai<2 (from pandasai)\n",
            "  Downloading openai-1.44.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pandas==1.5.3 (from pandasai)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pillow<11.0.0,>=10.1.0 (from pandasai)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from pandasai) (2.8.2)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.0 (from pandasai)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pandasai) (2.32.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from pandasai) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from pandasai) (2.0.32)\n",
            "Collecting sqlglot<26.0.0,>=25.0.3 (from sqlglot[rs]<26.0.0,>=25.0.3->pandasai)\n",
            "  Downloading sqlglot-25.20.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->pandasai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->pandasai) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->pandasai) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->pandasai) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (3.1.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2->pandasai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2->pandasai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2->pandasai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2->pandasai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2->pandasai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2->pandasai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai<2->pandasai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->pandasai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->pandasai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4->pandasai) (3.0.3)\n",
            "Collecting sqlglotrs==0.2.12 (from sqlglot[rs]<26.0.0,>=25.0.3->pandasai)\n",
            "  Downloading sqlglotrs-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (546 bytes)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2->pandasai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2->pandasai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2->pandasai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3->pandasai) (1.16.0)\n",
            "Downloading pandasai-2.2.14-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.8/179.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading duckdb-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.44.0-py3-none-any.whl (367 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading sqlglot-25.20.1-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlglotrs-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (334 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.5/334.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sqlglotrs, sqlglot, python-dotenv, pillow, jiter, h11, duckdb, astor, pandas, httpcore, faker, httpx, openai, pandasai\n",
            "  Attempting uninstall: sqlglot\n",
            "    Found existing installation: sqlglot 20.11.0\n",
            "    Uninstalling sqlglot-20.11.0:\n",
            "      Successfully uninstalled sqlglot-20.11.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: duckdb\n",
            "    Found existing installation: duckdb 0.10.3\n",
            "    Uninstalling duckdb-0.10.3:\n",
            "      Successfully uninstalled duckdb-0.10.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.15.0 requires sqlglot<=20.11,>=20.8.0, but you have sqlglot 25.20.1 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires sqlglot<=20.11,>=18.12.0, but you have sqlglot 25.20.1 which is incompatible.\n",
            "malloy 2024.1091 requires duckdb<1.0.0,>=0.8.0, but you have duckdb 1.0.0 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astor-0.8.1 duckdb-1.0.0 faker-19.13.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.44.0 pandas-1.5.3 pandasai-2.2.14 pillow-10.4.0 python-dotenv-1.0.1 sqlglot-25.20.1 sqlglotrs-0.2.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pandas"
                ]
              },
              "id": "746ac48acb8b44a685a19964d10f1d64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.38 (from langchain)\n",
            "  Downloading langchain_core-0.2.38-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.116-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.38->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m942.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.38-py3-none-any.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.116-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: tenacity, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.16 langchain-core-0.2.38 langchain-text-splitters-0.2.4 langsmith-0.1.116 orjson-3.10.7 tenacity-8.5.0\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.1.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.2.38)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (0.1.116)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (8.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.0.7)\n",
            "Downloading langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.11.0 langchain-groq-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import ast\n",
        "import sys\n",
        "import json\n",
        "import uuid\n",
        "import logging\n",
        "import pandas as pd\n",
        "from pandasai import SmartDataframe\n",
        "from langchain_groq import ChatGroq\n",
        "from IPython.display import Markdown, display\n",
        "from typing import List, Optional, Union, Dict\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import ChatPromptTemplate, FewShotPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
        "from langchain_core.messages import (\n",
        "                                      AIMessage,\n",
        "                                      BaseMessage,\n",
        "                                      HumanMessage,\n",
        "                                      SystemMessage,\n",
        "                                      ToolMessage,\n",
        "                                    )"
      ],
      "metadata": {
        "id": "fX1vGo5zMHFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Root Directory of the csv file attached for the second task\n",
        "task_2_dir = 'task2'"
      ],
      "metadata": {
        "id": "9RLTjrK-Ni5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 1. Data Handling & Examination**"
      ],
      "metadata": {
        "id": "hGn1OYvNtXqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file\n",
        "task_2_df = pd.read_csv(os.path.join(task_2_dir, 'task2.csv'))"
      ],
      "metadata": {
        "id": "t3pcZAWsMWdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_2_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mgAbVZ4FNCFW",
        "outputId": "64d3df62-170b-424f-b55f-4d147216840b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cell_no  hour  month  day  year  Bandwidth  counter_0  counter_1  \\\n",
              "0        0     0      6   12  2019         10     470620     367862   \n",
              "1        0     1      6   12  2019         10     129657      80729   \n",
              "2        0     2      6   12  2019         10      28839      18523   \n",
              "3        0     3      6   12  2019         10      17751      17845   \n",
              "4        0     4      6   12  2019         10      42836      35334   \n",
              "\n",
              "   counter_2  counter_3  counter_4  \\\n",
              "0     214295       3592     123759   \n",
              "1      37125       2698      72283   \n",
              "2       7949          1      21925   \n",
              "3       5292          0      10683   \n",
              "4      12739          0      24262   \n",
              "\n",
              "                                           counter_5  \n",
              "0  [0.0, 513392.0, 792138.0, 47284.0, 22429.0, 15...  \n",
              "1  [0.0, 1886861.0, 1579023.0, 67836.0, 23810.0, ...  \n",
              "2  [0.0, 2024560.0, 1288489.0, 213675.0, 33865.0,...  \n",
              "3  [0.0, 2089627.0, 1239282.0, 231054.0, 18927.0,...  \n",
              "4  [0.0, 2064013.0, 1355993.0, 132165.0, 18483.0,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7a51a68-aa96-44c6-b4cc-93efc8277007\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_no</th>\n",
              "      <th>hour</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>Bandwidth</th>\n",
              "      <th>counter_0</th>\n",
              "      <th>counter_1</th>\n",
              "      <th>counter_2</th>\n",
              "      <th>counter_3</th>\n",
              "      <th>counter_4</th>\n",
              "      <th>counter_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>10</td>\n",
              "      <td>470620</td>\n",
              "      <td>367862</td>\n",
              "      <td>214295</td>\n",
              "      <td>3592</td>\n",
              "      <td>123759</td>\n",
              "      <td>[0.0, 513392.0, 792138.0, 47284.0, 22429.0, 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>10</td>\n",
              "      <td>129657</td>\n",
              "      <td>80729</td>\n",
              "      <td>37125</td>\n",
              "      <td>2698</td>\n",
              "      <td>72283</td>\n",
              "      <td>[0.0, 1886861.0, 1579023.0, 67836.0, 23810.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>10</td>\n",
              "      <td>28839</td>\n",
              "      <td>18523</td>\n",
              "      <td>7949</td>\n",
              "      <td>1</td>\n",
              "      <td>21925</td>\n",
              "      <td>[0.0, 2024560.0, 1288489.0, 213675.0, 33865.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>10</td>\n",
              "      <td>17751</td>\n",
              "      <td>17845</td>\n",
              "      <td>5292</td>\n",
              "      <td>0</td>\n",
              "      <td>10683</td>\n",
              "      <td>[0.0, 2089627.0, 1239282.0, 231054.0, 18927.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>10</td>\n",
              "      <td>42836</td>\n",
              "      <td>35334</td>\n",
              "      <td>12739</td>\n",
              "      <td>0</td>\n",
              "      <td>24262</td>\n",
              "      <td>[0.0, 2064013.0, 1355993.0, 132165.0, 18483.0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7a51a68-aa96-44c6-b4cc-93efc8277007')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c7a51a68-aa96-44c6-b4cc-93efc8277007 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c7a51a68-aa96-44c6-b4cc-93efc8277007');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-deeecd8d-d033-4afb-aca6-45e3da2fecb4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-deeecd8d-d033-4afb-aca6-45e3da2fecb4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-deeecd8d-d033-4afb-aca6-45e3da2fecb4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "task_2_df"
            }
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the names of the columns associated with that csv file\n",
        "task_2_df.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrF4P_dtROZT",
        "outputId": "5dff3964-138d-41fc-cd8d-c1082eb49b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cell_no', 'hour', 'month', 'day', 'year', 'Bandwidth', 'counter_0',\n",
              "       'counter_1', 'counter_2', 'counter_3', 'counter_4', 'counter_5'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the datatypes of the columns associated with that csv file\n",
        "task_2_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "dwXZJAzMRRI6",
        "outputId": "427fc524-5c0d-409e-b877-cba977844221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cell_no       int64\n",
              "hour          int64\n",
              "month         int64\n",
              "day           int64\n",
              "year          int64\n",
              "Bandwidth     int64\n",
              "counter_0     int64\n",
              "counter_1     int64\n",
              "counter_2     int64\n",
              "counter_3     int64\n",
              "counter_4     int64\n",
              "counter_5    object\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cell_no</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hour</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>day</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bandwidth</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_0</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_1</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_2</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_3</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_4</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_5</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the dataframe\n",
        "task_2_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4rHLOjqRUs7",
        "outputId": "ddc89331-1da0-4d5d-b1bc-db9bb5b5a3dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(711432, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for any null values in that csv file\n",
        "task_2_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "ILvVOy2iRmE6",
        "outputId": "a33ebe87-027d-4302-8f5a-92acfb18a8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cell_no      0\n",
              "hour         0\n",
              "month        0\n",
              "day          0\n",
              "year         0\n",
              "Bandwidth    0\n",
              "counter_0    0\n",
              "counter_1    0\n",
              "counter_2    0\n",
              "counter_3    0\n",
              "counter_4    0\n",
              "counter_5    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cell_no</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hour</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>day</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bandwidth</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter_5</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the csv file\n",
        "task_2_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "lgWOMrtqRonU",
        "outputId": "bcc304e0-106b-43fa-b1fb-9e43be8cfe88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             cell_no           hour     month            day      year  \\\n",
              "count  711432.000000  711432.000000  711432.0  711432.000000  711432.0   \n",
              "mean     5052.316264      11.500000       6.0      13.003340    2019.0   \n",
              "std      2917.269491       6.922191       0.0       0.815932       0.0   \n",
              "min         0.000000       0.000000       6.0      12.000000    2019.0   \n",
              "25%      2529.000000       5.750000       6.0      12.000000    2019.0   \n",
              "50%      5064.000000      11.500000       6.0      13.000000    2019.0   \n",
              "75%      7589.000000      17.250000       6.0      14.000000    2019.0   \n",
              "max     10086.000000      23.000000       6.0      14.000000    2019.0   \n",
              "\n",
              "           Bandwidth     counter_0     counter_1     counter_2     counter_3  \\\n",
              "count  711432.000000  7.114320e+05  7.114320e+05  7.114320e+05  7.114320e+05   \n",
              "mean       13.946632  7.768739e+05  7.296818e+05  2.716741e+05  6.563258e+03   \n",
              "std         4.887786  1.310864e+06  1.152211e+06  4.136660e+05  2.190204e+04   \n",
              "min        10.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "25%        10.000000  2.467000e+04  2.563800e+04  1.727100e+04  0.000000e+00   \n",
              "50%        10.000000  2.850315e+05  2.820030e+05  1.038480e+05  3.060000e+02   \n",
              "75%        20.000000  1.076867e+06  1.036334e+06  3.603205e+05  3.685000e+03   \n",
              "max        20.000000  1.105076e+08  1.678519e+08  6.603080e+06  1.307764e+06   \n",
              "\n",
              "          counter_4  \n",
              "count  7.114320e+05  \n",
              "mean   2.678636e+05  \n",
              "std    4.624766e+05  \n",
              "min    0.000000e+00  \n",
              "25%    1.483000e+04  \n",
              "50%    8.408250e+04  \n",
              "75%    3.351872e+05  \n",
              "max    1.003652e+07  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6203f0dc-989e-4e4c-b78c-2556248ade41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_no</th>\n",
              "      <th>hour</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>Bandwidth</th>\n",
              "      <th>counter_0</th>\n",
              "      <th>counter_1</th>\n",
              "      <th>counter_2</th>\n",
              "      <th>counter_3</th>\n",
              "      <th>counter_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>711432.000000</td>\n",
              "      <td>711432.000000</td>\n",
              "      <td>711432.0</td>\n",
              "      <td>711432.000000</td>\n",
              "      <td>711432.0</td>\n",
              "      <td>711432.000000</td>\n",
              "      <td>7.114320e+05</td>\n",
              "      <td>7.114320e+05</td>\n",
              "      <td>7.114320e+05</td>\n",
              "      <td>7.114320e+05</td>\n",
              "      <td>7.114320e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5052.316264</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.003340</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>13.946632</td>\n",
              "      <td>7.768739e+05</td>\n",
              "      <td>7.296818e+05</td>\n",
              "      <td>2.716741e+05</td>\n",
              "      <td>6.563258e+03</td>\n",
              "      <td>2.678636e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2917.269491</td>\n",
              "      <td>6.922191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.815932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.887786</td>\n",
              "      <td>1.310864e+06</td>\n",
              "      <td>1.152211e+06</td>\n",
              "      <td>4.136660e+05</td>\n",
              "      <td>2.190204e+04</td>\n",
              "      <td>4.624766e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2529.000000</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>2.467000e+04</td>\n",
              "      <td>2.563800e+04</td>\n",
              "      <td>1.727100e+04</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.483000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5064.000000</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>2.850315e+05</td>\n",
              "      <td>2.820030e+05</td>\n",
              "      <td>1.038480e+05</td>\n",
              "      <td>3.060000e+02</td>\n",
              "      <td>8.408250e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7589.000000</td>\n",
              "      <td>17.250000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>1.076867e+06</td>\n",
              "      <td>1.036334e+06</td>\n",
              "      <td>3.603205e+05</td>\n",
              "      <td>3.685000e+03</td>\n",
              "      <td>3.351872e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10086.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>1.105076e+08</td>\n",
              "      <td>1.678519e+08</td>\n",
              "      <td>6.603080e+06</td>\n",
              "      <td>1.307764e+06</td>\n",
              "      <td>1.003652e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6203f0dc-989e-4e4c-b78c-2556248ade41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6203f0dc-989e-4e4c-b78c-2556248ade41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6203f0dc-989e-4e4c-b78c-2556248ade41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-728ee7b3-ec5f-4e2d-b299-c49e84abad34\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-728ee7b3-ec5f-4e2d-b299-c49e84abad34')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-728ee7b3-ec5f-4e2d-b299-c49e84abad34 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"task_2_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"cell_no\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 249869.7627180688,\n        \"min\": 0.0,\n        \"max\": 711432.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5052.3162635360795,\n          5064.0,\n          711432.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 251525.36122580396,\n        \"min\": 0.0,\n        \"max\": 711432.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          711432.0,\n          11.5,\n          17.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 251527.37751073655,\n        \"min\": 0.0,\n        \"max\": 711432.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          711432.0,\n          6.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 251525.21483941464,\n        \"min\": 0.8159323560089634,\n        \"max\": 711432.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          711432.0,\n          13.003339742940998,\n          14.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 250918.3410211093,\n        \"min\": 0.0,\n        \"max\": 711432.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          711432.0,\n          2019.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bandwidth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 251524.7090151737,\n        \"min\": 4.887785649739575,\n        \"max\": 711432.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          13.946631582498398,\n          20.0,\n          4.887785649739575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"counter_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38861787.90876743,\n        \"min\": 0.0,\n        \"max\": 110507553.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          776873.891009963,\n          285031.5,\n          711432.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"counter_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59147319.032046914,\n        \"min\": 0.0,\n        \"max\": 167851893.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          729681.7926323246,\n          282003.0,\n          711432.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"counter_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2252018.221236465,\n        \"min\": 0.0,\n        \"max\": 6603080.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          271674.14310011355,\n          103848.0,\n          711432.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"counter_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 491464.13577273476,\n        \"min\": 0.0,\n        \"max\": 1307764.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          711432.0,\n          6563.257837713232,\n          3685.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"counter_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3462140.9843276083,\n        \"min\": 0.0,\n        \"max\": 10036516.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          267863.618361277,\n          84082.5,\n          711432.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 2. First Approach: Using LLama 3 & PandasAI Integration**"
      ],
      "metadata": {
        "id": "dw5yuHdPthJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to chat with CSV data\n",
        "def chat_with_csv(df, query):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to convert the text to pandas query directly using LLM\n",
        "\n",
        "    Parameters:\n",
        "    df: The df of the csv file we are interested in.\n",
        "    query: The provided user query (text).\n",
        "\n",
        "    Returns:\n",
        "    result: The response to the query.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # API Key to be able to use the LLama3 Model\n",
        "    groq_api_key = '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'\n",
        "\n",
        "    # Initializing GROQ chat with provided API key, model name, and settings\n",
        "    llm = ChatGroq(\n",
        "                    groq_api_key=groq_api_key,\n",
        "                    model_name=\"llama3-70b-8192\",\n",
        "                    temperature=0.2)\n",
        "\n",
        "    # Initialize SmartDataframe with DataFrame and LLM configuration\n",
        "    pandas_ai = SmartDataframe(df, config={\"llm\": llm})\n",
        "    # Chat with the DataFrame using the provided query\n",
        "    result = pandas_ai.chat(query)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "Q3zPXGHZLv_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_engine_first_approach(df):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to run the engine of the first approach\n",
        "\n",
        "    Parameters:\n",
        "    df: The df from the csv file we are interested in.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Display a message to the user & wait for the user's input\n",
        "    input_text = input(\"Enter the query: \")\n",
        "\n",
        "    # Perform analysis\n",
        "    if input_text:\n",
        "            print(\"Your Query: \"+ input_text, \"\\n\")\n",
        "            result = chat_with_csv(df, input_text)\n",
        "            # Print the result of the query\n",
        "            print(\"Result: \" + str(result), \"\\n\")\n",
        "    else:\n",
        "            print(\"No query provided.\")"
      ],
      "metadata": {
        "id": "UVYRjJo_F4Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the cell to try the first approach\n",
        "run_engine_first_approach(task_2_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHgJH06QGI8A",
        "outputId": "0d2a3f58-375e-46a2-ad7e-d647f21c32cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the query: \"What is the maximum value for counter_2 for all of the cells?\n",
            "Your Query: \"What is the maximum value for counter_2 for all of the cells? \n",
            "\n",
            "Result: 6603080 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 3. Second Approach: Using LLama 3 For Query Parsing & Mapping the Parsed Data with the Predefined Pandas Commands**"
      ],
      "metadata": {
        "id": "ooxoHgsstw5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_query(query):\n",
        "\n",
        "  \"\"\"\n",
        "    Function to parse the query(user input/text) using LLM (LLama3 specifically)\n",
        "\n",
        "    Parameters:\n",
        "    query: The provided user query (text).\n",
        "\n",
        "    Returns:\n",
        "    llm_output: This represents the AI Message after parsing the query and following the template we created.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  # Initializing GROQ chat with provided API key, model name, and settings\n",
        "  groq_api_key = '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'\n",
        "  llm = ChatGroq(\n",
        "                  groq_api_key=groq_api_key,\n",
        "                  model_name=\"llama3-70b-8192\",\n",
        "                  temperature=0.2)\n",
        "\n",
        "\n",
        "  # How you would like your response structured.\n",
        "  response_schemas = [\n",
        "                      ResponseSchema(name=\"column\", description=\"The column to perform the operation on\"),\n",
        "                      ResponseSchema(name=\"filter_condition\", description=\"The filter condition if available, if not available place NULL\"),\n",
        "                      ResponseSchema(name=\"group_by\", description=\"The group by condition if available for example by cell or column, if not available place NULL\"),\n",
        "                      ResponseSchema(name=\"aggregation\", description=\"The type of aggregation to perform after grouping either: max, min, mean, sum, count, if not available place NULL\"),\n",
        "                      ResponseSchema(name=\"descriptive_statistics\", description=\"The basic statistics to perform either: count, mean, median, mode, standard deviation, and percentiles. if not available place NULL\"),\n",
        "                      ResponseSchema(name=\"summary_statistics\", description=\"The summary statistics of the df either: describe, corr, cov. if not available place NULL\"),\n",
        "                      ResponseSchema(name=\"unique_condition\", description=\"Either nunique to count the distinct values, unique to return a list of distinct values , or value_countsto shows the frequency of each unique value. If not mentioned place NULL\"),\n",
        "\n",
        "                      ResponseSchema(name=\"add_column\", description=\"The name of the column we want to add, if not mentioned any addition of columns then place NULL\"),\n",
        "                      ResponseSchema(name=\"drop_column\", description=\"The name of the column we want to drop, if not mentioned any dropping or removal of columns then place NULL\"),\n",
        "\n",
        "                      ResponseSchema(name=\"fillna\", description=\"The value/number that fills the missing or NaN values in the df, If not mentioned place NULL\"),\n",
        "                      ResponseSchema(name=\"dropna\", description=\"The name of the column that contain missing values (NaN) from the df, if not mentioned any sorting then place with NULL\"),\n",
        "\n",
        "                      ResponseSchema(name=\"sort_order\", description=\"The order to sort by the data either ascending or descinding, if not mentioned any sorting then place with NULL\"),\n",
        "                      ResponseSchema(name=\"sort_column\", description=\"The column to sort by, if not mentioned any sorting then place with NULL\"),\n",
        "                   ]\n",
        "\n",
        "\n",
        "\n",
        "  # How you would like to parse your output (Format of the parsed data)\n",
        "  output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "  format_instructions = output_parser.get_format_instructions()\n",
        "  # See the prompt template you created for formatting\n",
        "  #print ('Format Instructions: ', format_instructions)\n",
        "\n",
        "  # A template for your LLM to work on (can be seen as simply an instructions to your Large Language Model)\n",
        "  template = f\"\"\"\n",
        "                You will be given a user pandas query in the form of text.\n",
        "                Extract all the useful information from it to be able to perform the query.\n",
        "                Keep in mind that the dataframe has the following columns: {str(list(task_2_df.columns))}.\n",
        "                \"\"\" + \"\"\"\n",
        "                Use the provided columns to identify if the user query wants to filter based on one of the columns or group the cells based on them.\n",
        "                When the user pandas query mentions the word for all cells it is talking about the cell_no column, so be careful the group_by condition may not be null.\n",
        "                The filter condition if available should be in a form for pandas query to understand, such as: \"filter_condition\": \"year > 2019\".\n",
        "                If the query wants to perform operations on several columns for example the median of each feature in the dataset, then make the column in the form of: column_1, column_2, column_3. Where each column represents the features/columns in the dataframe\n",
        "\n",
        "                Return the output as a valid JSON object, ensuring all commas between key-value pairs are present.\n",
        "\n",
        "                {format_instructions}\n",
        "\n",
        "                % USER INPUT:\n",
        "                {user_input}\n",
        "\n",
        "                YOUR RESPONSE:\n",
        "                \"\"\"\n",
        "\n",
        "\n",
        "  # Create a prompt template that takes the user input (query/text), the format we want from the output (information retrieved from the query in the form of a json)\n",
        "  prompt = PromptTemplate(\n",
        "                          input_variables=[\"user_input\"],\n",
        "                          partial_variables={\"format_instructions\": format_instructions},\n",
        "                          template=template\n",
        "                         )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  promptValue = prompt.format(user_input=query)\n",
        "  # print(promptValue)\n",
        "\n",
        "  # Use the LLM with the instructions made (template) to parse the data\n",
        "  llm_output = llm.invoke(promptValue)\n",
        "\n",
        "  # print(\"Result (AI Message): \\n\" , llm_output)\n",
        "  llm_output_text = llm_output.content\n",
        "  # print(\"AI Message's Content: \\n\" , type(llm_output_text), \"AI Message's Content: \\n\" , llm_output_text)\n",
        "\n",
        "  try:\n",
        "    json_string = llm_output_text.replace('json', '')\n",
        "\n",
        "    # Remove the backticks and clean the string\n",
        "    json_string = json_string.replace('```', '').strip()\n",
        "\n",
        "    # Further cleanup: Replace 'NULL' with 'null' to make it JSON-compatible\n",
        "    json_string = json_string.replace('NULL', 'null')\n",
        "\n",
        "    # Parse the cleaned JSON string\n",
        "    parsed_output = json.loads(json_string)\n",
        "\n",
        "    return parsed_output\n",
        "\n",
        "  except json.JSONDecodeError as e:\n",
        "      print(f\"Error parsing JSON: {e}\")\n",
        "      return None"
      ],
      "metadata": {
        "id": "uyaGG9ksqXT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to apply operations based on parsed output\n",
        "def apply_operations(df, parsed_output):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to apply operations(pandas queries) based on the parsed output from the LLM\n",
        "\n",
        "    Parameters:\n",
        "    df: The df from the csv file we are interested in.\n",
        "    parsed_output: The parsed output from the LLM as a dictionary.\n",
        "\n",
        "    Returns:\n",
        "    df: The updated dataframe after applying the queries.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Dictionary to map operations to pandas commands\n",
        "    pandas_operations = {\n",
        "\n",
        "                          # For general descriptive statistics (within a certain column range)\n",
        "                          \"max\": lambda df, column: df[column].max(),\n",
        "                          \"min\": lambda df, column: df[column].min(),\n",
        "                          \"sum\": lambda df, column: df[column].sum(),\n",
        "                          \"mean\": lambda df, column: df[column].mean(),\n",
        "                          \"median\": lambda df, column: df[column].median(),\n",
        "                          \"mode\": lambda df, column: df[column].mode(),\n",
        "                          \"count\": lambda df, column: df[column].count(),\n",
        "\n",
        "                          # For Filtering operation\n",
        "                          \"filter_condition\": lambda df, condition: df.query(condition),\n",
        "\n",
        "                          # For sorting operation\n",
        "                          \"sort\": lambda df, column, sort_order: df.sort_values(by=column, ascending=(sort_order == 'ascending')),\n",
        "\n",
        "\n",
        "                          # For aggregation operations\n",
        "                          \"group_by_sum\": lambda df, column, group_by: df.groupby(group_by)[column].sum(),\n",
        "                          \"group_by_min\": lambda df, column, group_by: df.groupby(group_by)[column].min(),\n",
        "                          \"group_by_max\": lambda df, column, group_by: df.groupby(group_by)[column].max(),\n",
        "                          \"group_by_mean\": lambda df, column, group_by: df.groupby(group_by)[column].mean(),\n",
        "                          \"group_by_count\": lambda df, column, group_by: df.groupby(group_by)[column].count(),\n",
        "\n",
        "                          # For Unique Operations\n",
        "                          \"value_counts\": lambda df, column: df[column].value_counts(),\n",
        "                          \"nunique\": lambda df, column: df[column].nunique(),\n",
        "                          \"unique\": lambda df, column: df[column].unique(),\n",
        "\n",
        "\n",
        "                          # Summary Statistics (within the df range)\n",
        "                          \"describe\": lambda df: df.describe(),\n",
        "                          \"corr\": lambda df: df.corr(),\n",
        "                          \"cov\": lambda df: df.cov(),\n",
        "\n",
        "\n",
        "                          # Dropping & Adding Columns\n",
        "                          \"add_column\": lambda df, column, value: df.assign(**{column: value}),\n",
        "                          \"drop_column\": lambda df, column: df.drop(columns=[column]),\n",
        "\n",
        "                          # Removing Null valued records or filling them with values\n",
        "                          \"fillna\": lambda df, column, value: df[column].fillna(value),\n",
        "                          \"dropna\": lambda df, column: df.dropna(subset=[column]),\n",
        "                      }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Retrieve the information from the parsed output\n",
        "    column = parsed_output.get('column')\n",
        "    filter_condition = parsed_output.get('filter_condition')\n",
        "    group_by = parsed_output.get('group_by')\n",
        "    aggregation = parsed_output.get('aggregation')\n",
        "\n",
        "    summary_statistics = parsed_output.get('summary_statistics')\n",
        "    descriptive_statistics = parsed_output.get('descriptive_statistics')\n",
        "\n",
        "    unique_condition = parsed_output.get('unique_condition')\n",
        "\n",
        "    add_column = parsed_output.get('add_column')\n",
        "    drop_column = parsed_output.get('drop_column')\n",
        "\n",
        "    fillna = parsed_output.get('fillna')\n",
        "    dropna = parsed_output.get('dropna')\n",
        "\n",
        "    sort_order = parsed_output.get('sort_order')\n",
        "    sort_column = parsed_output.get('sort_column')\n",
        "\n",
        "\n",
        "    # Apply filter on df if condition is present\n",
        "    if filter_condition:\n",
        "        df = pandas_operations[\"filter_condition\"](df, filter_condition)\n",
        "\n",
        "    # Apply grouping and aggregation if the conditions are present\n",
        "    if group_by:\n",
        "        if aggregation in [\"max\", \"min\", \"mean\", \"sum\", \"count\"]:\n",
        "            df = pandas_operations[f\"group_by_{aggregation}\"](df, column, group_by)\n",
        "        else:\n",
        "            raise ValueError(f\"Operation '{aggregation}' not supported with grouping.\")\n",
        "\n",
        "    # If the query doesn't mention grouping then check for basic operations on the individual columns\n",
        "    else:\n",
        "        # If the query doesn't mention grouping\n",
        "        if descriptive_statistics in [\"max\", \"min\", \"mean\", \"mode\", \"median\", \"sum\", \"count\"]:\n",
        "            df = pandas_operations[descriptive_statistics](df, column)\n",
        "        if summary_statistics in [\"describe\", \"cov\", \"corr\"]:\n",
        "            df = pandas_operations[summary_statistics](df, column)\n",
        "        if add_column:\n",
        "            df = pandas_operations[\"add_column\"](df, add_column)\n",
        "        if drop_column:\n",
        "            df = pandas_operations[\"drop_column\"](df, drop_column)\n",
        "        if fillna:\n",
        "            df = pandas_operations[\"fillna\"](df, column, fillna)\n",
        "        if dropna:\n",
        "            df = pandas_operations[\"dropna\"](df, dropna)\n",
        "        elif unique_condition in [\"value_counts\", \"nunique\",  \"unique\"]:\n",
        "            df = pandas_operations[unique_condition](df, column)\n",
        "        # else:\n",
        "        #     raise ValueError(f\"Operation not supported.\")\n",
        "\n",
        "    # If the query mentions sorting\n",
        "    if sort_order:\n",
        "        df = pandas_operations['sort'](df, sort_column, sort_order)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "wBjPw1KmJmcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to apply operations based on parsed output\n",
        "def run_engine_second_approach(df):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to run the engine of the second approach\n",
        "\n",
        "    Parameters:\n",
        "    df: The df from the csv file we are interested in.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Display a message to the user & wait for the user's input\n",
        "    input_text = input(\"Enter the query: \")\n",
        "    parsed_output = {}\n",
        "\n",
        "    # Perform analysis\n",
        "    if input_text:\n",
        "            # Pass the user's query to the parsing function & get the AI Message with the parsed data\n",
        "            parsed_output = parse_query(str(input_text))\n",
        "\n",
        "            # Print the user's query\n",
        "            print(\"Your Query: \"+ input_text, \"\\n\")\n",
        "\n",
        "            # Print the parsed output\n",
        "            print(\"The Parsed Data:\\n \", parsed_output, \"\\n\")\n",
        "    else:\n",
        "            print(\"No query provided.\")\n",
        "\n",
        "    # Initialize DataFrame\n",
        "    df_result = df.copy()\n",
        "\n",
        "    # Execute the operations\n",
        "    result_df = apply_operations(df_result, parsed_output)\n",
        "\n",
        "    # print the result of the query\n",
        "    print('Result of the query: \\n', result_df, \"\\n\")"
      ],
      "metadata": {
        "id": "E2dOdxeWE_9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the cell to try the second approach\n",
        "run_engine_second_approach(task_2_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaYtMsvafTf2",
        "outputId": "8a206779-1b75-44fd-c080-789b6638acc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the query: \"What is the maximum value for counter_2 for all of the cells?\n",
            "Your Query: \"What is the maximum value for counter_2 for all of the cells? \n",
            "\n",
            "The Parsed Data:\n",
            "  {'column': 'counter_2', 'filter_condition': None, 'group_by': 'cell_no', 'aggregation': 'max', 'descriptive_statistics': None, 'summary_statistics': None, 'unique_condition': None, 'add_column': None, 'drop_column': None, 'fillna': None, 'dropna': None, 'sort_order': None, 'sort_column': None} \n",
            "\n",
            "Result of the query: \n",
            " cell_no\n",
            "0         552616\n",
            "1          33622\n",
            "2         162759\n",
            "3          17776\n",
            "4            422\n",
            "          ...   \n",
            "10082     890310\n",
            "10083     239447\n",
            "10084     882536\n",
            "10085    1415453\n",
            "10086    1319282\n",
            "Name: counter_2, Length: 10041, dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 4. How to Evaluate & Optimize our engine**\n",
        "\n",
        "The evaluation of any application is an **iterative** process and it involves several key components which can be divided as follows:\n",
        "\n",
        "1. An evolving evaluation dataset that is continuously improving over time, the dataset should be of high quality (no noise, no missing or null values, ..etc) , a very important aspect is that it should be representative.\n",
        "\n",
        "2. Choosing and implementing a set of relevant evaluation metrics like precision, recall, accuracy or even time of response depending on application.\n",
        "\n",
        "3. Establishing a strong evaluation infrastructure allows for continuous, real-time assessments throughout the entire lifecycle of your LLM application.\n",
        "\n",
        "In our Case the evaluation of the \"Text2PandasEngine\" will depend solely on the evaluation of how the input text / user query is parsed, since the quality of the parsed data would affect how the mapping of the commands would work.\n",
        "\n",
        "Given that the parsing of our data was done by the help of a LLM (specifically LLama3) by incorporating its abilities in the Information Retrieval (IR), our evaluation process would include evaluating its abilities in the IR, and subsequently improving its performance in our application by updating our prompt template to ensure the proper parsing of data.\n",
        "\n",
        "### **Evaluation of the quality of parsed data**\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#### **A. Evolving Evaluation Dataset**\n",
        "\n",
        "An evaluation dataset, also called a golden dataset or ground truth, is crucial for assessing any system's performance. Creating such a dataset involves significant cost and time, as it requires selecting diverse inputs across various scenarios and complexities to ensure the system can generalize well. The golden dataset serves as a benchmark for evaluating the system's capabilities, and identifying improvement areas. There is no strict rule for the number of examples needed, but it's important to cover edge cases. Even a small set of 10-50 examples can be valuable, and additional examples can be added over time to enhance the dataset. For our case we can collect an intial small dataset, the dataset would be in the form of user query, which would represent our input X, and the corresponding expected parsed data (dictionary of values), which would be our target Y, the golden data can be collected from any one for example the data analysts or scientists working in the company. The data can always be updated at anytime so starting with a small amount of data is not a big deal. Another way of collecting data would be the preproduction or predeployment phases, where we can use the engine and provide a section for the evaluation/feedback of the users (the fastest way to collect data, but be careful of the noise).\n",
        "\n",
        "\n",
        "\n",
        "#### **B. Evaluation Metrics**\n",
        "\n",
        "After creating our dataset, we can now define some metrics to evaluate our responses on. Since we have an expected answer, we can compare to that as part of our evaluation. Choosing the accuracy, which would represent the amount of correctly parsed data, as an evaluation metric would be a good starting point.\n",
        "\n",
        "\n",
        "\n",
        "#### **C. Evaluation Infrastructure**\n",
        "\n",
        "General speaking we could have multiple approaches for that:\n",
        "\n",
        "\n",
        "**1. Practice of eyeballing:**\n",
        "\n",
        "The most basic straight forward approach, however not the most reliable if we would to speak on a broader level. This involves experimenting with a few inputs and expected responses, and subsequently improving our system by trying various prompt templates. In general this case would introduce the highest quality output (at the expense of time) since it would depend on the human expertise, however given that our output isn't like a natural language text (our output has a definite structure and values) thus it wouldn't be advised to take that approach.\n",
        "\n",
        "In our case the Parsed Data should have the same structure (keys) but with different values:\n",
        "\n",
        "**e.g.**\n",
        "\n",
        "{ 'column': 'counter_2',\n",
        "    'filter_condition': None,\n",
        "    'group_by': 'cell_no',\n",
        "    'aggregation': 'max',\n",
        "    'descriptive_statistics': None,\n",
        "    'summary_statistics': None,\n",
        "    'unique_condition': None,\n",
        "    'add_column': None,\n",
        "    'drop_column': None,\n",
        "    'fillna': None,\n",
        "    'dropna': None,\n",
        "    'sort_order': None,\n",
        "    'sort_column': None\n",
        "}\n",
        "\n",
        "So if the process of comparing the values was automated we would be saving time, human resources (maybe at the expense of computational resources) while also maintaining high quality evaluation.\n",
        "\n",
        "\n",
        "\n",
        "**2. AI evaluating AI:**\n",
        "\n",
        "A very common approach, and can be thought of as the optimal approach in our case. This approach would make use of other llms to evaluate the quality of our parsed data by leveraging the power of prompt templates. So how would this work ? well after having our own golden standard dataset we will then use a llm of our choice along with our llm-based engine and using prompts we would instruct the chosen llm to evaluate the parsed data from the pandas engine by giving it both the golden dataset and the output of the pandas engine. There are a lot of frameworks for doing so, for example: LangSmith by LangChain.\n",
        "\n",
        "**\"For more details  =>  https://docs.smith.langchain.com/tutorials/Developers/evaluation \"**\n",
        "\n",
        "\n",
        "\n",
        "**Remember Evaluation is an iterative process , repeat the cycle even after deployment :)**\n",
        "\n",
        "\n",
        "\n",
        "### **Improving the quality of parsed data**\n",
        "---\n",
        "\n",
        "After evaluating the model you can always improve it, and since the evaluation is an iterative process it would be clear that also the system's updating would be iterative (similar to how versions of programs are present). The updating can be based on the data collected from the feedback and then modifying the prompt template given to our application's / engine's llm (LLama3, the one used in the system) to be able to handle new queries & then evaluating again."
      ],
      "metadata": {
        "id": "-qo04vsuOgRQ"
      }
    }
  ]
}